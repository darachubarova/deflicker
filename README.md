# Mask Stabilization System (Defliker TM)

**ĞĞ²Ñ‚Ğ¾Ñ€:** Ğ§ÑƒĞ±Ğ°Ñ€Ğ¾Ğ²Ğ° Ğ”Ğ°Ñ€ÑŒÑ ĞĞ»ĞµĞºÑĞµĞµĞ²Ğ½Ğ°

A complete system for reducing flickering in frame-by-frame video segmentation using temporal smoothing techniques.

## ğŸŒ Project Presentation

**Live Demo:** [https://github.com/darachubarova/defliker](https://https://github.com/darachubarova/deflicker/)

A comprehensive presentation website (in Russian) showcasing:
- Problem statement and visual explanations
- System architecture and technologies
- Stabilization methods with formulas
- Experimental results and metrics
- API documentation
- Q&A section for homework defense

See [docs/GITHUB_PAGES_SETUP.md](docs/GITHUB_PAGES_SETUP.md) for GitHub Pages setup instructions.

## ğŸ“‹ Overview

This project implements a full pipeline for:
1. **Video Segmentation** using DeepLabv3 (PyTorch/torchvision)
2. **Mask Stabilization** with multiple temporal smoothing methods
3. **Metrics Calculation** to measure stability improvements
4. **REST API** for easy integration (FastAPI)
5. **Interactive Analysis** with Jupyter notebooks

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Upload    â”‚â”€â”€â”€â”€â”€â–¶â”‚ Segmentation â”‚â”€â”€â”€â”€â”€â–¶â”‚  Stabilization  â”‚
â”‚    Video    â”‚      â”‚  (DeepLabv3) â”‚      â”‚   (Temporal)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                        â”‚
                            â”‚                        â”‚
                            â–¼                        â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚    Masks     â”‚        â”‚  Smoothed   â”‚
                     â”‚   (Before)   â”‚        â”‚   Masks     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â”‚
                                                     â–¼
                                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                             â”‚   Metrics   â”‚
                                             â”‚ Calculation â”‚
                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
mask-stabilization/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ Dockerfile                   # Docker container setup
â”œâ”€â”€ docker-compose.yml           # Docker composition
â”‚
â”œâ”€â”€ docs/                        # Presentation website (GitHub Pages)
â”‚   â”œâ”€â”€ index.html               # Main presentation page (Russian)
â”‚   â””â”€â”€ GITHUB_PAGES_SETUP.md    # Setup instructions
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI server
â”‚   â”œâ”€â”€ segmentation.py          # DeepLabv3 segmentation
â”‚   â”œâ”€â”€ stabilization.py         # Temporal smoothing methods
â”‚   â”œâ”€â”€ metrics.py               # Stability metrics (IoU, etc.)
â”‚   â””â”€â”€ utils.py                 # Utility functions
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb           # Interactive analysis notebook
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html               # Web frontend (HTML/CSS/JS)
â”‚   â””â”€â”€ README.md                # Frontend documentation
â”‚
â”œâ”€â”€ spark_frontend/
â”‚   â””â”€â”€ SPARK_PROMPT.md          # GitHub Spark frontend prompt
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ .gitkeep                 # Place test videos here
â”‚
â””â”€â”€ results/
    â””â”€â”€ .gitkeep                 # Processing results stored here
```

## ğŸš€ Installation

### Option 1: Local Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/darachubarova/defliker.git
   cd mask-stabilization
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

### Option 2: Docker

1. **Build and run with Docker Compose**
   ```bash
   docker-compose up --build
   ```

The API will be available at `http://localhost:8000`

## ğŸ“– Usage

### Running the API Server

```bash
# From the project root directory
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

Access the API documentation at `http://localhost:8000/docs`

### Using the Jupyter Notebook

```bash
jupyter notebook notebooks/analysis.ipynb
```

The notebook provides a step-by-step demonstration of the entire pipeline.

### API Endpoints

#### 1. Upload Video
```bash
curl -X POST "http://localhost:8000/api/upload" \
  -F "file=@path/to/video.mp4"
```

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "uploaded",
  "video_info": {
    "fps": 30.0,
    "frame_count": 150,
    "width": 1920,
    "height": 1080
  }
}
```

#### 2. Segment Video
```bash
curl -X POST "http://localhost:8000/api/segment" \
  -H "Content-Type: application/json" \
  -d '{"job_id": "YOUR_JOB_ID", "target_class": "person"}'
```

#### 3. Apply Stabilization
```bash
curl -X POST "http://localhost:8000/api/stabilize" \
  -H "Content-Type: application/json" \
  -d '{
    "job_id": "YOUR_JOB_ID",
    "method": "moving_average",
    "window_size": 5
  }'
```

#### 4. Get Status
```bash
curl "http://localhost:8000/api/status/YOUR_JOB_ID"
```

#### 5. Get Metrics
```bash
curl "http://localhost:8000/api/metrics/YOUR_JOB_ID"
```

**Response:**
```json
{
  "iou_before": {
    "mean": 0.8234,
    "std": 0.0521,
    "min": 0.6543,
    "max": 0.9876
  },
  "iou_after": {
    "mean": 0.9123,
    "std": 0.0234,
    "min": 0.8234,
    "max": 0.9912
  },
  "improvement": {
    "iou_improvement": 0.0889,
    "iou_improvement_percent": 10.8,
    "instability_reduction_percent": 57.3
  }
}
```

#### 6. Get Frame Image
```bash
curl "http://localhost:8000/api/frames/YOUR_JOB_ID/comparison/25" \
  --output frame_25.png
```

Frame types: `mask_before`, `mask_after`, `comparison`

### Available Segmentation Classes

```python
{
    0: 'background',
    15: 'person',
    7: 'car',
    6: 'bus',
    8: 'truck',
    9: 'boat',
    17: 'cat',
    18: 'dog',
    19: 'horse',
    20: 'sheep',
    21: 'cow'
}
```

## ğŸ”¬ Stabilization Methods

### 1. Moving Average
Averages probability maps over a temporal window.

**Parameters:**
- `window_size`: 3, 5, 7, or 9 (must be odd)

**Formula:**
```
smoothed[i] = mean(masks[i-w:i+w+1])
```

**Use case:** General-purpose smoothing, good balance between smoothness and responsiveness.

### 2. Median Filter
Computes median across temporal window for each pixel.

**Parameters:**
- `window_size`: 3, 5, 7, or 9 (must be odd)

**Formula:**
```
smoothed[i] = median(masks[i-w:i+w+1])
```

**Use case:** Robust to outliers, preserves sharp edges better than moving average.

### 3. Exponential Smoothing
Weighted average giving more importance to recent frames.

**Parameters:**
- `alpha`: 0.1 to 0.9 (smoothing factor)
  - Lower Î± = more smoothing
  - Higher Î± = more responsive

**Formula:**
```
smoothed[t] = Î± * original[t] + (1-Î±) * smoothed[t-1]
```

**Use case:** Adaptive smoothing, good for varying motion speeds.

## ğŸ“Š Metrics

### IoU (Intersection over Union)
Measures overlap between consecutive frames:
```
IoU = |A âˆ© B| / |A âˆª B|
```

Higher IoU = more temporal consistency

### Instability Score
```
Instability = 1 - IoU
```

Higher instability = more flickering

### Metrics Computed

- **Mean IoU**: Average consistency across all frame transitions
- **IoU Standard Deviation**: Variability in consistency
- **Instability Reduction**: Percentage decrease in flickering
- **Min/Max IoU**: Range of consistency values

## ğŸ¨ Frontend

A clean, modern web interface is available in the `frontend/` directory.

### Quick Start

1. **Start the API server:**
   ```bash
   uvicorn src.main:app --host 0.0.0.0 --port 8000
   ```

2. **Open the frontend:**
   - Simply open `frontend/index.html` in a web browser, or
   - Serve it with a simple HTTP server:
     ```bash
     cd frontend
     python -m http.server 8080
     ```
   - Navigate to `http://localhost:8080/index.html`

### Features

The frontend provides:
- **Drag-and-drop video upload** with format validation
- **Real-time processing status** with progress tracking
- **Interactive frame viewer** with navigation controls
- **Metrics visualization** showing IoU improvements
- **Configuration options** for object classes and stabilization methods
- **Responsive design** that works on all screen sizes

See `frontend/README.md` for detailed documentation.

For an alternative GitHub Spark interface, see the prompt in `spark_frontend/SPARK_PROMPT.md`.

## ğŸ” Example Workflow

1. **Upload a video**
2. **Segment** targeting "person" class
3. **Apply** moving average with window_size=5
4. **Visualize** results:
   - Frame-by-frame comparison
   - IoU improvement chart
   - Quantitative metrics

## ğŸ“ˆ Expected Results

Typical improvements with window_size=5:

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Mean IoU | 0.823 | 0.912 | +10.8% |
| IoU Std | 0.052 | 0.023 | -55.8% |
| Instability | 0.177 | 0.088 | -50.3% |

## ğŸ› ï¸ Development

### Running Tests

```bash
# Add tests in tests/ directory
pytest tests/
```

### Code Structure

- `segmentation.py`: VideoSegmenter class using DeepLabv3
- `stabilization.py`: MaskStabilizer with temporal filtering methods
- `metrics.py`: Metric calculation functions
- `utils.py`: Helper functions for video/image processing
- `main.py`: FastAPI application with REST endpoints

## ğŸ“ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is for educational purposes (Homework Assignment 5).

## ğŸ™ Acknowledgments

- DeepLabv3 model from torchvision
- FastAPI framework
- OpenCV for video processing

## ğŸ“š References

- DeepLabv3: [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)
- Temporal consistency in video segmentation
- Moving average and median filters for temporal smoothing

## ğŸ’¡ Tips

1. **Video Selection**: Start with short videos (5-10 seconds) for faster processing
2. **Class Selection**: Choose "person" for best results with human subjects
3. **Window Size**: Start with 5, increase for more smoothing
4. **Alpha Value**: Try 0.3 for balanced exponential smoothing

## ğŸ› Troubleshooting

**Issue**: CUDA out of memory
```python
# Solution: Use CPU mode or reduce batch size
segmenter = VideoSegmenter(device='cpu')
```

**Issue**: Video won't upload
- Check file format (.mp4, .avi, .mov supported)
- Ensure file size < 100MB
- Verify video codec compatibility

**Issue**: Segmentation is slow
- Use GPU if available
- Reduce video resolution
- Process fewer frames

## ğŸ“ Support

For issues and questions, please open an issue on GitHub.

---

**Status**: âœ… Ready for deployment and testing

**Version**: 1.0.0

**Last Updated**: December 2025
